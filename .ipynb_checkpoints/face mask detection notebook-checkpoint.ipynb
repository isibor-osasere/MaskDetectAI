{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884db434-60d8-49dd-841a-085133da2d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b45804c-5204-4b87-a3d9-06d34a570b6b",
   "metadata": {},
   "source": [
    "### Data observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f7b09fe-e8da-4236-96a3-f7c4db60af83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 88C6-D8B5\n",
      "\n",
      " Directory of C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\n",
      "\n",
      "11/11/2024  06:25 AM    <DIR>          .\n",
      "11/11/2024  05:30 AM    <DIR>          ..\n",
      "11/11/2024  06:11 AM    <DIR>          .ipynb_checkpoints\n",
      "11/11/2024  06:25 AM            11,067 face mask detection yolov11.ipynb\n",
      "11/11/2024  06:08 AM               636 face_mask.yaml\n",
      "11/11/2024  05:26 AM    <DIR>          face_mask_splitted\n",
      "11/11/2024  06:13 AM    <DIR>          runs\n",
      "11/11/2024  05:33 AM    <DIR>          Untitled Folder\n",
      "11/11/2024  06:13 AM               627 Untitled.ipynb\n",
      "11/11/2024  05:14 AM        51,387,343 yolo11l.pt\n",
      "               4 File(s)     51,399,673 bytes\n",
      "               6 Dir(s)   9,183,379,456 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "668b0ca1-de1d-48b9-b7d5-a47eca4ccfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\yolov8-cpu-env\\lib\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "C:\\Users\\hp\\anaconda3\\envs\\yolov8-cpu-env\\lib\\site-packages\\IPython\\core\\magics\\osm.py:428: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5127f869-4aff-498f-8364-44f11c7eacb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\n"
     ]
    }
   ],
   "source": [
    "# get the absolute path\n",
    "import os\n",
    "print (os.getcwd ())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a8d0e5-17e5-49a7-b813-4547a72b95a6",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b071df-5a49-46cc-8e48-a638ebf0f86a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.28  Python-3.10.6 torch-2.5.1+cpu CPU (Intel Core(TM) i5-6300U 2.40GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11l.pt, data=C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\face_mask.yaml, epochs=15, time=None, patience=20, batch=8, imgsz=416, save=True, save_period=1, cache=False, device=cpu, workers=8, project=None, name=yolov11_face_mask3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\yolov11_face_mask3\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1413337  ultralytics.nn.modules.head.Detect           [3, [256, 512, 512]]          \n",
      "YOLO11l summary: 631 layers, 25,312,793 parameters, 25,312,777 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\yolov11_face_mask3', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\face_mask_splitted\\labels\\train.cache... 640 images, 0 backgrounds, 0 corrupt: 100%|██████████| 640/640 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\face_mask_splitted\\labels\\val.cache... 80 images, 0 backgrounds, 0 corrupt: 100%|██████████| 80/80 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\yolov11_face_mask3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\yolov11_face_mask3\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/15         0G      1.526      1.417      1.194         66        416: 100%|██████████| 80/80 [21:09<00:00, 15.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:45<00:00,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353       0.43      0.489      0.449       0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/15         0G      1.333      1.028      1.106         49        416: 100%|██████████| 80/80 [19:49<00:00, 14.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:41<00:00,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.699      0.413      0.343      0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/15         0G      1.317     0.9953      1.091         70        416: 100%|██████████| 80/80 [26:06<00:00, 19.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [01:10<00:00, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.278      0.337      0.222      0.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/15         0G      1.328     0.9496       1.09         62        416: 100%|██████████| 80/80 [33:31<00:00, 25.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [01:10<00:00, 14.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.358       0.64      0.453      0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/15         0G      1.303     0.8919       1.08         65        416: 100%|██████████| 80/80 [33:31<00:00, 25.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [01:09<00:00, 13.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.719      0.601      0.647      0.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/15         0G      1.246     0.8435      1.067         26        416: 100%|██████████| 80/80 [4:57:07<00:00, 222.85s/it]    \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:41<00:00,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.646      0.589      0.627      0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/15         0G      1.227      0.814       1.07         45        416: 100%|██████████| 80/80 [19:44<00:00, 14.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:42<00:00,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353        0.7      0.612      0.656      0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/15         0G      1.225     0.7834      1.061         21        416: 100%|██████████| 80/80 [22:48<00:00, 17.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:43<00:00,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.815       0.65      0.722      0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/15         0G       1.17     0.7225      1.041         52        416: 100%|██████████| 80/80 [22:27<00:00, 16.84s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:42<00:00,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.764      0.618      0.686      0.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:03<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your pre-trained model\n",
    "model = YOLO('yolo11l.pt')\n",
    "\n",
    "model.train(\n",
    "    data='C:\\\\Users\\\\hp\\\\Osasere_data_science\\\\opencv_beginner_2\\\\yolov8-cpu\\\\face_mask.yaml',\n",
    "    imgsz=416,\n",
    "    workers=8,\n",
    "    batch=8,\n",
    "    device=\"cpu\",\n",
    "    epochs=15,  # Total number of epochs\n",
    "    patience=20,  # Number of epochs without improvement before early stopping\n",
    "    name='yolov11_face_mask',\n",
    "    save_period=1  # Save weights after every epoch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce293c89-9e4e-499b-aba8-f15c9d00bfa4",
   "metadata": {},
   "source": [
    "### Training yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a2461-5f5d-4ca4-82e7-669bde9be07c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.28  Python-3.10.6 torch-2.5.1+cpu CPU (Intel Core(TM) i5-6300U 2.40GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\face_mask.yaml, epochs=15, time=None, patience=20, batch=8, imgsz=640, save=True, save_period=1, cache=False, device=cpu, workers=8, project=None, name=yolov8s_face_mask, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\yolov8s_face_mask\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11,136,761 parameters, 11,136,745 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\yolov8s_face_mask', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\face_mask_splitted\\labels\\train.cache... 640 images, 0 backgrounds, 0 corrupt: 100%|██████████| 640/640 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\yolov8-cpu\\face_mask_splitted\\labels\\val.cache... 80 images, 0 backgrounds, 0 corrupt: 100%|██████████| 80/80 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\yolov8s_face_mask\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\yolov8s_face_mask\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/15         0G      1.582      1.796      1.332         66        640: 100%|██████████| 80/80 [16:38<00:00, 12.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:34<00:00,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.593       0.55      0.534      0.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/15         0G      1.262     0.9689        1.1         49        640: 100%|██████████| 80/80 [16:47<00:00, 12.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:33<00:00,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353       0.84       0.48      0.587      0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/15         0G      1.249     0.8948      1.093         70        640: 100%|██████████| 80/80 [16:01<00:00, 12.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:33<00:00,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.722      0.542      0.631      0.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/15         0G      1.284     0.8585      1.095         62        640: 100%|██████████| 80/80 [16:15<00:00, 12.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:33<00:00,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.781      0.615      0.692      0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/15         0G      1.212     0.7997       1.07         67        640: 100%|██████████| 80/80 [16:10<00:00, 12.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:33<00:00,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.616      0.786      0.732      0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/15         0G      1.182     0.7717      1.085         26        640: 100%|██████████| 80/80 [15:56<00:00, 11.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:32<00:00,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.887      0.688      0.765      0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/15         0G      1.159     0.7551      1.075         45        640: 100%|██████████| 80/80 [16:18<00:00, 12.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:34<00:00,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.824      0.691      0.737      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/15         0G      1.154     0.7041      1.065         21        640: 100%|██████████| 80/80 [15:49<00:00, 11.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:33<00:00,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.888      0.716       0.81      0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/15         0G      1.107     0.6601      1.056         52        640: 100%|██████████| 80/80 [15:54<00:00, 11.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:33<00:00,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.833      0.737      0.812      0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/15         0G       1.12     0.6393      1.045         18        640: 100%|██████████| 80/80 [19:39<00:00, 14.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:40<00:00,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.916      0.722      0.797      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/15         0G      1.081     0.5979       1.03         69        640: 100%|██████████| 80/80 [4:46:28<00:00, 214.86s/it]   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:45<00:00,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.903      0.737      0.803      0.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/15         0G      1.078     0.5808      1.036         49        640: 100%|██████████| 80/80 [26:33<00:00, 19.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:55<00:00, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.876      0.757      0.842      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/15         0G      1.051      0.559      1.015         41        640: 100%|██████████| 80/80 [27:29<00:00, 20.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:55<00:00, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        353      0.929      0.768      0.843      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/15         0G      1.019     0.5333     0.9907         47        640:  48%|████▊     | 38/80 [12:56<14:12, 20.31s/it]"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your pre-trained model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "model.train(\n",
    "    data='C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/face_mask_detection_project/face_mask.yaml',\n",
    "    imgsz=640,\n",
    "    workers=8,\n",
    "    batch=8,\n",
    "    device=\"cpu\",\n",
    "    epochs=15,  # Total number of epochs\n",
    "    patience=20,  # Number of epochs without improvement before early stopping\n",
    "    name='yolov8s_face_mask',\n",
    "    save_period=1  # Save weights after every epoch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa1a269-7526-43f1-966b-d1e6fd5a0f4d",
   "metadata": {},
   "source": [
    "### Continue model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8e06f-cd19-417a-babe-a6bc4af987a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## from ultralytics import YOLO\n",
    "\n",
    "# Load your pre-trained model\n",
    "model = YOLO('C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/face_mask_detection_project/runs/detect/yolov8s_face_mask/weights/last.pt')\n",
    "\n",
    "# Resume training\n",
    "model.train(\n",
    "    data='C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/face_mask_detection_project/face_mask.yaml',\n",
    "    imgsz=640,\n",
    "    workers=8,\n",
    "    batch=8,\n",
    "    device=\"cpu\",\n",
    "    epochs=17,\n",
    "    patience=50,\n",
    "    name='yolov8s_face_mask',\n",
    "    save_period = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdcc8e0-142a-4678-815e-bacd64f14cb1",
   "metadata": {},
   "source": [
    "### Making predictions on custom test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac798b34-2697-44f7-a631-64bbb5ab6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/10 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\test_images\\maksssksksss13.png: 256x416 8 Masks, 470.0ms\n",
      "image 2/10 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\test_images\\maksssksksss19.png: 256x416 4 Masks, 1 No Mask, 348.0ms\n",
      "image 3/10 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\test_images\\maksssksksss2.png: 320x416 4 Masks, 507.9ms\n",
      "image 4/10 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\test_images\\maksssksksss33.png: 416x288 1 Mask, 484.2ms\n",
      "image 5/10 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\test_images\\maksssksksss43.png: 416x288 1 Mask, 393.3ms\n",
      "image 6/10 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\test_images\\maksssksksss5.png: 288x416 2 Masks, 2 No Masks, 441.8ms\n",
      "image 7/10 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\test_images\\maksssksksss53.png: 256x416 4 Masks, 382.8ms\n",
      "image 8/10 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\test_images\\maksssksksss6.png: 288x416 1 Mask, 391.0ms\n",
      "image 9/10 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\test_images\\maksssksksss66.png: 416x416 1 Mask, 606.3ms\n",
      "image 10/10 C:\\Users\\hp\\Osasere_data_science\\opencv_beginner_2\\test_images\\maksssksksss75.png: 224x416 12 Masks, 375.6ms\n",
      "Speed: 0.5ms preprocess, 440.1ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict4\u001b[0m\n",
      "10 labels saved to runs\\detect\\predict4\\labels\n"
     ]
    }
   ],
   "source": [
    "# Load the model with the latest trained weights\n",
    "model = YOLO('C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/runs/detect/yolov11_face_mask3/weights/best.pt')  # Use the path to your best or final weights\n",
    "\n",
    "# Define the path to your test images\n",
    "test_image_path = 'C:/Users/hp/Osasere_data_science/opencv_beginner_2/test_images/*.png'  # Use wildcard for batch prediction\n",
    "\n",
    "# Run predictions\n",
    "results = model.predict(\n",
    "    source=test_image_path,   # Folder or specific image path\n",
    "    imgsz=416,                # Image size\n",
    "    conf=0.5,                 # Confidence threshold (0-1)\n",
    "    save=True,                # Save predictions\n",
    "    save_txt=True             # Save predictions as text files (optional)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685a52b-dedd-424e-ace9-7888145dbf0c",
   "metadata": {},
   "source": [
    "### Making predictions on custom videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9391afc5-97dc-4e66-9c3d-cfd46d298a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 No Mask, 452.0ms\n",
      "Speed: 5.5ms preprocess, 452.0ms inference, 13.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 449.9ms\n",
      "Speed: 10.3ms preprocess, 449.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 410.9ms\n",
      "Speed: 7.6ms preprocess, 410.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 386.4ms\n",
      "Speed: 0.0ms preprocess, 386.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 390.6ms\n",
      "Speed: 6.7ms preprocess, 390.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 392.2ms\n",
      "Speed: 0.0ms preprocess, 392.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 374.3ms\n",
      "Speed: 2.4ms preprocess, 374.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 405.1ms\n",
      "Speed: 3.7ms preprocess, 405.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 384.6ms\n",
      "Speed: 3.0ms preprocess, 384.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 364.3ms\n",
      "Speed: 0.0ms preprocess, 364.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 371.4ms\n",
      "Speed: 1.6ms preprocess, 371.4ms inference, 15.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 362.3ms\n",
      "Speed: 2.9ms preprocess, 362.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 359.4ms\n",
      "Speed: 3.7ms preprocess, 359.4ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 361.6ms\n",
      "Speed: 1.9ms preprocess, 361.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 362.6ms\n",
      "Speed: 4.5ms preprocess, 362.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 382.8ms\n",
      "Speed: 2.4ms preprocess, 382.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 379.5ms\n",
      "Speed: 4.5ms preprocess, 379.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 388.8ms\n",
      "Speed: 8.0ms preprocess, 388.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 379.1ms\n",
      "Speed: 0.9ms preprocess, 379.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 371.8ms\n",
      "Speed: 4.3ms preprocess, 371.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 363.7ms\n",
      "Speed: 4.3ms preprocess, 363.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 352.9ms\n",
      "Speed: 1.3ms preprocess, 352.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 351.0ms\n",
      "Speed: 5.3ms preprocess, 351.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 355.8ms\n",
      "Speed: 2.7ms preprocess, 355.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 357.0ms\n",
      "Speed: 1.0ms preprocess, 357.0ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 360.4ms\n",
      "Speed: 1.9ms preprocess, 360.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 No Mask, 362.0ms\n",
      "Speed: 4.6ms preprocess, 362.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 364.8ms\n",
      "Speed: 4.4ms preprocess, 364.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 587.3ms\n",
      "Speed: 1.3ms preprocess, 587.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 360.0ms\n",
      "Speed: 6.9ms preprocess, 360.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 369.4ms\n",
      "Speed: 2.2ms preprocess, 369.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 352.7ms\n",
      "Speed: 4.1ms preprocess, 352.7ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 366.9ms\n",
      "Speed: 1.3ms preprocess, 366.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 381.5ms\n",
      "Speed: 3.7ms preprocess, 381.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 371.2ms\n",
      "Speed: 1.4ms preprocess, 371.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 354.0ms\n",
      "Speed: 5.1ms preprocess, 354.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 357.5ms\n",
      "Speed: 2.0ms preprocess, 357.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 364.1ms\n",
      "Speed: 3.0ms preprocess, 364.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 359.4ms\n",
      "Speed: 3.9ms preprocess, 359.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 374.8ms\n",
      "Speed: 3.7ms preprocess, 374.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 368.5ms\n",
      "Speed: 3.7ms preprocess, 368.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 365.5ms\n",
      "Speed: 1.4ms preprocess, 365.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 350.3ms\n",
      "Speed: 2.6ms preprocess, 350.3ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 361.1ms\n",
      "Speed: 5.7ms preprocess, 361.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 346.7ms\n",
      "Speed: 2.3ms preprocess, 346.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 No Mask, 343.3ms\n",
      "Speed: 1.7ms preprocess, 343.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 362.0ms\n",
      "Speed: 1.3ms preprocess, 362.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 350.5ms\n",
      "Speed: 4.6ms preprocess, 350.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 365.7ms\n",
      "Speed: 1.4ms preprocess, 365.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 371.6ms\n",
      "Speed: 1.8ms preprocess, 371.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 378.9ms\n",
      "Speed: 3.9ms preprocess, 378.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 362.6ms\n",
      "Speed: 4.7ms preprocess, 362.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 357.4ms\n",
      "Speed: 4.8ms preprocess, 357.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 368.7ms\n",
      "Speed: 4.3ms preprocess, 368.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 373.0ms\n",
      "Speed: 6.1ms preprocess, 373.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 371.6ms\n",
      "Speed: 4.7ms preprocess, 371.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 373.9ms\n",
      "Speed: 2.7ms preprocess, 373.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 No Mask, 360.0ms\n",
      "Speed: 6.5ms preprocess, 360.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 363.7ms\n",
      "Speed: 3.5ms preprocess, 363.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 358.8ms\n",
      "Speed: 3.7ms preprocess, 358.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 357.6ms\n",
      "Speed: 1.9ms preprocess, 357.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 353.0ms\n",
      "Speed: 4.2ms preprocess, 353.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 366.2ms\n",
      "Speed: 4.1ms preprocess, 366.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 374.1ms\n",
      "Speed: 1.4ms preprocess, 374.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 374.1ms\n",
      "Speed: 4.5ms preprocess, 374.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 369.0ms\n",
      "Speed: 2.8ms preprocess, 369.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 360.4ms\n",
      "Speed: 4.3ms preprocess, 360.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 350.8ms\n",
      "Speed: 4.1ms preprocess, 350.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 No Mask, 347.9ms\n",
      "Speed: 4.1ms preprocess, 347.9ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 No Mask, 364.9ms\n",
      "Speed: 3.2ms preprocess, 364.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 359.6ms\n",
      "Speed: 4.6ms preprocess, 359.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 423.2ms\n",
      "Speed: 4.7ms preprocess, 423.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 391.5ms\n",
      "Speed: 2.2ms preprocess, 391.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 378.1ms\n",
      "Speed: 5.1ms preprocess, 378.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 373.3ms\n",
      "Speed: 2.8ms preprocess, 373.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 370.7ms\n",
      "Speed: 1.7ms preprocess, 370.7ms inference, 16.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 423.2ms\n",
      "Speed: 2.0ms preprocess, 423.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 370.1ms\n",
      "Speed: 3.7ms preprocess, 370.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 367.4ms\n",
      "Speed: 4.3ms preprocess, 367.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 372.3ms\n",
      "Speed: 5.8ms preprocess, 372.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 370.8ms\n",
      "Speed: 5.0ms preprocess, 370.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 358.9ms\n",
      "Speed: 5.2ms preprocess, 358.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 369.1ms\n",
      "Speed: 3.8ms preprocess, 369.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 353.4ms\n",
      "Speed: 5.1ms preprocess, 353.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 374.5ms\n",
      "Speed: 3.0ms preprocess, 374.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 374.2ms\n",
      "Speed: 5.4ms preprocess, 374.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 394.9ms\n",
      "Speed: 3.9ms preprocess, 394.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 455.2ms\n",
      "Speed: 6.5ms preprocess, 455.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 352.5ms\n",
      "Speed: 5.3ms preprocess, 352.5ms inference, 14.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 354.2ms\n",
      "Speed: 2.5ms preprocess, 354.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 357.5ms\n",
      "Speed: 6.4ms preprocess, 357.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 346.5ms\n",
      "Speed: 4.2ms preprocess, 346.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 352.1ms\n",
      "Speed: 0.0ms preprocess, 352.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 348.0ms\n",
      "Speed: 1.5ms preprocess, 348.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 356.5ms\n",
      "Speed: 4.2ms preprocess, 356.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 360.8ms\n",
      "Speed: 3.5ms preprocess, 360.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 366.2ms\n",
      "Speed: 5.3ms preprocess, 366.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 356.2ms\n",
      "Speed: 1.5ms preprocess, 356.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 363.0ms\n",
      "Speed: 3.2ms preprocess, 363.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 629.5ms\n",
      "Speed: 4.7ms preprocess, 629.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 371.7ms\n",
      "Speed: 3.5ms preprocess, 371.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 347.6ms\n",
      "Speed: 4.0ms preprocess, 347.6ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 354.9ms\n",
      "Speed: 4.4ms preprocess, 354.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 345.4ms\n",
      "Speed: 4.2ms preprocess, 345.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 No Masks, 361.4ms\n",
      "Speed: 0.0ms preprocess, 361.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 352.9ms\n",
      "Speed: 2.7ms preprocess, 352.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 375.7ms\n",
      "Speed: 2.9ms preprocess, 375.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 376.3ms\n",
      "Speed: 4.6ms preprocess, 376.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 361.1ms\n",
      "Speed: 4.7ms preprocess, 361.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 374.8ms\n",
      "Speed: 4.8ms preprocess, 374.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 355.4ms\n",
      "Speed: 4.7ms preprocess, 355.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 361.4ms\n",
      "Speed: 1.4ms preprocess, 361.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 368.2ms\n",
      "Speed: 5.2ms preprocess, 368.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 360.4ms\n",
      "Speed: 1.9ms preprocess, 360.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 369.2ms\n",
      "Speed: 0.0ms preprocess, 369.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 362.4ms\n",
      "Speed: 3.7ms preprocess, 362.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 361.3ms\n",
      "Speed: 2.3ms preprocess, 361.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 358.6ms\n",
      "Speed: 1.7ms preprocess, 358.6ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 370.7ms\n",
      "Speed: 5.6ms preprocess, 370.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 377.3ms\n",
      "Speed: 6.3ms preprocess, 377.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 375.2ms\n",
      "Speed: 5.3ms preprocess, 375.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 375.1ms\n",
      "Speed: 4.0ms preprocess, 375.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 362.3ms\n",
      "Speed: 4.0ms preprocess, 362.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 378.2ms\n",
      "Speed: 3.6ms preprocess, 378.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 375.9ms\n",
      "Speed: 0.0ms preprocess, 375.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 362.4ms\n",
      "Speed: 4.8ms preprocess, 362.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 359.8ms\n",
      "Speed: 5.9ms preprocess, 359.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 359.3ms\n",
      "Speed: 4.1ms preprocess, 359.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 357.4ms\n",
      "Speed: 4.8ms preprocess, 357.4ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 373.2ms\n",
      "Speed: 1.8ms preprocess, 373.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 370.8ms\n",
      "Speed: 4.1ms preprocess, 370.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 377.7ms\n",
      "Speed: 4.4ms preprocess, 377.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 374.5ms\n",
      "Speed: 6.2ms preprocess, 374.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 382.5ms\n",
      "Speed: 5.6ms preprocess, 382.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 365.2ms\n",
      "Speed: 4.9ms preprocess, 365.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 357.1ms\n",
      "Speed: 3.3ms preprocess, 357.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 364.9ms\n",
      "Speed: 4.2ms preprocess, 364.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 368.0ms\n",
      "Speed: 2.2ms preprocess, 368.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 354.4ms\n",
      "Speed: 1.8ms preprocess, 354.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 363.7ms\n",
      "Speed: 4.0ms preprocess, 363.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 360.5ms\n",
      "Speed: 4.2ms preprocess, 360.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 356.9ms\n",
      "Speed: 5.0ms preprocess, 356.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 373.1ms\n",
      "Speed: 4.4ms preprocess, 373.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 376.2ms\n",
      "Speed: 4.8ms preprocess, 376.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 372.4ms\n",
      "Speed: 1.9ms preprocess, 372.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 361.6ms\n",
      "Speed: 7.7ms preprocess, 361.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 381.0ms\n",
      "Speed: 2.9ms preprocess, 381.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 365.8ms\n",
      "Speed: 4.9ms preprocess, 365.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 574.9ms\n",
      "Speed: 4.6ms preprocess, 574.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 364.9ms\n",
      "Speed: 3.1ms preprocess, 364.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 357.0ms\n",
      "Speed: 4.2ms preprocess, 357.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 359.1ms\n",
      "Speed: 2.9ms preprocess, 359.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Bad Masks, 372.4ms\n",
      "Speed: 2.1ms preprocess, 372.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 373.9ms\n",
      "Speed: 1.4ms preprocess, 373.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 Bad Mask, 366.0ms\n",
      "Speed: 6.3ms preprocess, 366.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 374.2ms\n",
      "Speed: 3.6ms preprocess, 374.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 359.0ms\n",
      "Speed: 6.8ms preprocess, 359.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 Bad Mask, 366.6ms\n",
      "Speed: 5.0ms preprocess, 366.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 365.4ms\n",
      "Speed: 2.9ms preprocess, 365.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 Bad Mask, 354.8ms\n",
      "Speed: 5.3ms preprocess, 354.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 Bad Mask, 346.2ms\n",
      "Speed: 1.1ms preprocess, 346.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 356.2ms\n",
      "Speed: 4.8ms preprocess, 356.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 370.4ms\n",
      "Speed: 0.0ms preprocess, 370.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 2 Bad Masks, 357.1ms\n",
      "Speed: 4.9ms preprocess, 357.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 Bad Mask, 375.7ms\n",
      "Speed: 4.9ms preprocess, 375.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 Bad Mask, 368.4ms\n",
      "Speed: 1.7ms preprocess, 368.4ms inference, 14.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 2 Bad Masks, 369.2ms\n",
      "Speed: 5.6ms preprocess, 369.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 Bad Mask, 359.9ms\n",
      "Speed: 4.5ms preprocess, 359.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 Bad Mask, 376.5ms\n",
      "Speed: 4.6ms preprocess, 376.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 Bad Mask, 374.5ms\n",
      "Speed: 4.9ms preprocess, 374.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 366.5ms\n",
      "Speed: 5.3ms preprocess, 366.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 363.8ms\n",
      "Speed: 3.9ms preprocess, 363.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 361.5ms\n",
      "Speed: 1.7ms preprocess, 361.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 368.5ms\n",
      "Speed: 5.2ms preprocess, 368.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 No Mask, 360.1ms\n",
      "Speed: 5.5ms preprocess, 360.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 366.4ms\n",
      "Speed: 3.8ms preprocess, 366.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 365.6ms\n",
      "Speed: 5.3ms preprocess, 365.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 368.8ms\n",
      "Speed: 3.6ms preprocess, 368.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 355.8ms\n",
      "Speed: 5.8ms preprocess, 355.8ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 365.6ms\n",
      "Speed: 6.4ms preprocess, 365.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Bad Mask, 361.4ms\n",
      "Speed: 4.9ms preprocess, 361.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 344.6ms\n",
      "Speed: 2.0ms preprocess, 344.6ms inference, 15.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 356.6ms\n",
      "Speed: 8.6ms preprocess, 356.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 361.9ms\n",
      "Speed: 2.6ms preprocess, 361.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 363.0ms\n",
      "Speed: 5.0ms preprocess, 363.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 362.7ms\n",
      "Speed: 5.0ms preprocess, 362.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 347.7ms\n",
      "Speed: 4.1ms preprocess, 347.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 361.9ms\n",
      "Speed: 5.3ms preprocess, 361.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 360.4ms\n",
      "Speed: 2.7ms preprocess, 360.4ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 358.4ms\n",
      "Speed: 7.0ms preprocess, 358.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 1 Bad Mask, 373.1ms\n",
      "Speed: 1.7ms preprocess, 373.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 372.8ms\n",
      "Speed: 4.6ms preprocess, 372.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 381.0ms\n",
      "Speed: 3.4ms preprocess, 381.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 357.9ms\n",
      "Speed: 7.4ms preprocess, 357.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 364.0ms\n",
      "Speed: 4.8ms preprocess, 364.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 359.1ms\n",
      "Speed: 2.6ms preprocess, 359.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 355.9ms\n",
      "Speed: 4.7ms preprocess, 355.9ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 353.0ms\n",
      "Speed: 0.0ms preprocess, 353.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 349.2ms\n",
      "Speed: 5.6ms preprocess, 349.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 375.6ms\n",
      "Speed: 4.1ms preprocess, 375.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 372.6ms\n",
      "Speed: 3.8ms preprocess, 372.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 377.4ms\n",
      "Speed: 4.1ms preprocess, 377.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 No Mask, 368.9ms\n",
      "Speed: 6.0ms preprocess, 368.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2, time\n",
    "\n",
    "# Choose source: 0 for webcam or provide a video file path\n",
    "source = \"C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/custom_face_mask_test/face_mask_test2.mp4\"\n",
    "\n",
    "# Load your trained YOLO model\n",
    "model = YOLO('C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/face_mask_detection_project/runs/detect/yolov8s_face_mask/weights/best.pt')\n",
    "\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the video source is opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video source.\")\n",
    "    exit()\n",
    "\n",
    "# Define video writer if you want to save the output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for mp4\n",
    "out = cv2.VideoWriter('test_results/output_video6.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Finished processing video or camera feed.\")\n",
    "        break\n",
    "\n",
    "    # Perform inference on the current frame\n",
    "    results = model(frame)\n",
    "\n",
    "    # Extract detected boxes and labels\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Display the output frame\n",
    "    cv2.imshow('Face Mask Detection', annotated_frame)\n",
    "\n",
    "    # Save the annotated frame\n",
    "    # writer for 30 fps\n",
    "    time.sleep (1/30)\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    # Press 'q' to exit the video display window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb18a0-a461-4cf6-9e44-87d9a54211b8",
   "metadata": {},
   "source": [
    "### Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd189b8-f8e0-4a5c-b64b-6b92c9beaffb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "source = \"C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/custom_face_mask_test/face_mask_test2.mp4\"\n",
    "model = YOLO ('C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/runs/detect/yolov8s_face_mask/weights/best.pt')\n",
    "\n",
    "# Define video writer if you want to save the output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for mp4\n",
    "out = cv2.VideoWriter('output_video2.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "cap = cv2.VideoCapture (source)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read ()\n",
    "    if not ret:\n",
    "        print (\"finished processing video or camera feed\")\n",
    "\n",
    "    # perform object tracking on current frame\n",
    "    results = model.track (frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4ebd9-14a7-4fec-a9ea-c6f193253e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "253542b3-18fc-4dd9-89ea-981d27c44783",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO ('C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/runs/detect/yolov8s_face_mask/weights/best.pt')\n",
    "source = \"C:/Users/hp/Osasere_data_science/opencv_beginner_2/yolov8-cpu/custom_face_mask_test/face_mask_test2.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655809ed-6594-499b-9384-4c6bf8d08a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yolov8-cpu-env)",
   "language": "python",
   "name": "yolov8-cpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
